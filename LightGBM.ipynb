{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPH3jw2SXc9MoZwxmsOft7u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**LightGBM Model**"],"metadata":{"id":"2n5-4G_-kGw_"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from lightgbm import LGBMClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, classification_report, make_scorer\n","import joblib\n","from google.colab import files\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.max_rows\", None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yScYOfwoj4JE","executionInfo":{"status":"ok","timestamp":1764004893877,"user_tz":-120,"elapsed":22220,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"6d1e9107-3e06-479e-ce5a-d5863689b4db"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df_main = pd.read_csv('/content/drive/MyDrive/dataset.csv')\n","df_main.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"id":"0HA1cGskkW8h","executionInfo":{"status":"ok","timestamp":1764004900390,"user_tz":-120,"elapsed":6510,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"99a7b059-3876-47de-c462-e4241adc2619"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n","0      100002         Cash loans           M            N               Y   \n","1      100003         Cash loans           F            N               N   \n","2      100004    Revolving loans           M            Y               Y   \n","3      100006         Cash loans           F            N               Y   \n","4      100007         Cash loans           M            N               Y   \n","5      100008         Cash loans           M            N               Y   \n","6      100009         Cash loans           F            Y               Y   \n","7      100010         Cash loans           M            Y               Y   \n","8      100012    Revolving loans           M            N               Y   \n","9      100014         Cash loans           F            N               Y   \n","\n","   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n","0             0          202500.0    406597.5      24700.5         351000.0   \n","1             0          270000.0   1293502.5      35698.5        1129500.0   \n","2             0           67500.0    135000.0       6750.0         135000.0   \n","3             0          135000.0    312682.5      29686.5         297000.0   \n","4             0          121500.0    513000.0      21865.5         513000.0   \n","5             0           99000.0    490495.5      27517.5         454500.0   \n","6             1          171000.0   1560726.0      41301.0        1395000.0   \n","7             0          360000.0   1530000.0      42075.0        1530000.0   \n","8             0          135000.0    405000.0      20250.0         405000.0   \n","9             1          112500.0    652500.0      21177.0         652500.0   \n","\n","   NAME_TYPE_SUITE      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n","0    Unaccompanied               Working  Secondary / secondary special   \n","1           Family         State servant               Higher education   \n","2    Unaccompanied               Working  Secondary / secondary special   \n","3    Unaccompanied               Working  Secondary / secondary special   \n","4    Unaccompanied               Working  Secondary / secondary special   \n","5  Spouse, partner         State servant  Secondary / secondary special   \n","6    Unaccompanied  Commercial associate               Higher education   \n","7    Unaccompanied         State servant               Higher education   \n","8    Unaccompanied               Working  Secondary / secondary special   \n","9    Unaccompanied               Working               Higher education   \n","\n","     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  REGION_POPULATION_RELATIVE  \\\n","0  Single / not married  House / apartment                    0.018801   \n","1               Married  House / apartment                    0.003541   \n","2  Single / not married  House / apartment                    0.010032   \n","3        Civil marriage  House / apartment                    0.008019   \n","4  Single / not married  House / apartment                    0.028663   \n","5               Married  House / apartment                    0.035792   \n","6               Married  House / apartment                    0.035792   \n","7               Married  House / apartment                    0.003122   \n","8  Single / not married  House / apartment                    0.019689   \n","9               Married  House / apartment                    0.022800   \n","\n","   OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  FLAG_CONT_MOBILE  \\\n","0          0.0           1               1                0                 1   \n","1          0.0           1               1                0                 1   \n","2         26.0           1               1                1                 1   \n","3          0.0           1               1                0                 1   \n","4          0.0           1               1                0                 1   \n","5          0.0           1               1                1                 1   \n","6         17.0           1               1                0                 1   \n","7          8.0           1               1                1                 1   \n","8          0.0           1               1                0                 1   \n","9          0.0           1               1                0                 1   \n","\n","   FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n","0           1           0        Laborers              1.0   \n","1           1           0      Core staff              2.0   \n","2           1           0        Laborers              1.0   \n","3           0           0        Laborers              2.0   \n","4           0           0      Core staff              1.0   \n","5           1           0        Laborers              2.0   \n","6           1           0     Accountants              3.0   \n","7           0           0        Managers              2.0   \n","8           0           0        Laborers              1.0   \n","9           0           0      Core staff              3.0   \n","\n","   REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n","0                     2                            2   \n","1                     1                            1   \n","2                     2                            2   \n","3                     2                            2   \n","4                     2                            2   \n","5                     2                            2   \n","6                     2                            2   \n","7                     3                            3   \n","8                     2                            2   \n","9                     2                            2   \n","\n","  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n","0                  WEDNESDAY                       10   \n","1                     MONDAY                       11   \n","2                     MONDAY                        9   \n","3                  WEDNESDAY                       17   \n","4                   THURSDAY                       11   \n","5                  WEDNESDAY                       16   \n","6                     SUNDAY                       16   \n","7                     MONDAY                       16   \n","8                   THURSDAY                        8   \n","9                   SATURDAY                       15   \n","\n","   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n","0                           0                           0   \n","1                           0                           0   \n","2                           0                           0   \n","3                           0                           0   \n","4                           0                           0   \n","5                           0                           0   \n","6                           0                           0   \n","7                           0                           0   \n","8                           0                           0   \n","9                           0                           0   \n","\n","   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n","0                            0                       0   \n","1                            0                       0   \n","2                            0                       0   \n","3                            0                       0   \n","4                            0                       0   \n","5                            0                       0   \n","6                            0                       0   \n","7                            0                       0   \n","8                            0                       0   \n","9                            0                       0   \n","\n","   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY       ORGANIZATION_TYPE  \\\n","0                       0                        0  Business Entity Type 3   \n","1                       0                        0                  School   \n","2                       0                        0              Government   \n","3                       0                        0  Business Entity Type 3   \n","4                       1                        1                Religion   \n","5                       0                        0                   Other   \n","6                       0                        0  Business Entity Type 3   \n","7                       1                        1                   Other   \n","8                       0                        0             Electricity   \n","9                       0                        0                Medicine   \n","\n","   EXT_SOURCE_2  EXT_SOURCE_3  OBS_30_CNT_SOCIAL_CIRCLE  \\\n","0      0.262949      0.139376                       2.0   \n","1      0.622246      0.544235                       1.0   \n","2      0.555912      0.729567                       0.0   \n","3      0.650442      0.515495                       2.0   \n","4      0.322738      0.492060                       0.0   \n","5      0.354225      0.621226                       0.0   \n","6      0.724000      0.492060                       1.0   \n","7      0.714279      0.540654                       2.0   \n","8      0.746644      0.492060                       2.0   \n","9      0.651862      0.363945                       0.0   \n","\n","   DEF_30_CNT_SOCIAL_CIRCLE  OBS_60_CNT_SOCIAL_CIRCLE  \\\n","0                       2.0                       2.0   \n","1                       0.0                       1.0   \n","2                       0.0                       0.0   \n","3                       0.0                       2.0   \n","4                       0.0                       0.0   \n","5                       0.0                       0.0   \n","6                       0.0                       1.0   \n","7                       0.0                       2.0   \n","8                       0.0                       2.0   \n","9                       0.0                       0.0   \n","\n","   DEF_60_CNT_SOCIAL_CIRCLE  FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  \\\n","0                       2.0                0                1   \n","1                       0.0                0                1   \n","2                       0.0                0                0   \n","3                       0.0                0                1   \n","4                       0.0                0                0   \n","5                       0.0                0                1   \n","6                       0.0                0                0   \n","7                       0.0                0                1   \n","8                       0.0                0                0   \n","9                       0.0                0                1   \n","\n","   FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  \\\n","0                0                0                0                0   \n","1                0                0                0                0   \n","2                0                0                0                0   \n","3                0                0                0                0   \n","4                0                0                0                0   \n","5                0                0                0                0   \n","6                0                0                0                0   \n","7                0                0                0                0   \n","8                0                0                0                0   \n","9                0                0                0                0   \n","\n","   FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  \\\n","0                0                0                 0                 0   \n","1                0                0                 0                 0   \n","2                0                0                 0                 0   \n","3                0                0                 0                 0   \n","4                1                0                 0                 0   \n","5                0                0                 0                 0   \n","6                1                0                 0                 0   \n","7                0                0                 0                 0   \n","8                0                0                 0                 0   \n","9                0                0                 0                 0   \n","\n","   FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  \\\n","0                 0                 0                 0                 0   \n","1                 0                 0                 0                 0   \n","2                 0                 0                 0                 0   \n","3                 0                 0                 0                 0   \n","4                 0                 0                 0                 0   \n","5                 0                 0                 0                 0   \n","6                 0                 0                 1                 0   \n","7                 0                 0                 0                 0   \n","8                 0                 0                 0                 0   \n","9                 0                 0                 0                 0   \n","\n","   FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  \\\n","0                 0                 0                 0                 0   \n","1                 0                 0                 0                 0   \n","2                 0                 0                 0                 0   \n","3                 0                 0                 0                 0   \n","4                 0                 0                 0                 0   \n","5                 0                 0                 0                 0   \n","6                 0                 0                 0                 0   \n","7                 0                 0                 0                 0   \n","8                 0                 0                 0                 0   \n","9                 0                 0                 0                 0   \n","\n","   FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n","0                 0                 0                         0.0   \n","1                 0                 0                         0.0   \n","2                 0                 0                         0.0   \n","3                 0                 0                         0.0   \n","4                 0                 0                         0.0   \n","5                 0                 0                         0.0   \n","6                 0                 0                         0.0   \n","7                 0                 0                         0.0   \n","8                 0                 0                         0.0   \n","9                 0                 0                         0.0   \n","\n","   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n","0                        0.0                         0.0   \n","1                        0.0                         0.0   \n","2                        0.0                         0.0   \n","3                        0.0                         0.0   \n","4                        0.0                         0.0   \n","5                        0.0                         0.0   \n","6                        0.0                         0.0   \n","7                        0.0                         0.0   \n","8                        0.0                         0.0   \n","9                        0.0                         0.0   \n","\n","   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n","0                        0.0                        0.0   \n","1                        0.0                        0.0   \n","2                        0.0                        0.0   \n","3                        0.0                        0.0   \n","4                        0.0                        0.0   \n","5                        0.0                        1.0   \n","6                        1.0                        1.0   \n","7                        0.0                        0.0   \n","8                        0.0                        0.0   \n","9                        1.0                        0.0   \n","\n","   AMT_REQ_CREDIT_BUREAU_YEAR  YEARS_BIRTH  YEARS_EMPLOYED  \\\n","0                         1.0    25.902806        1.744011   \n","1                         0.0    45.900068        3.252567   \n","2                         0.0    52.145106        0.616016   \n","3                         2.0    52.032854        8.320329   \n","4                         0.0    54.570842        8.317591   \n","5                         1.0    46.381930        4.347707   \n","6                         2.0    37.722108        8.569473   \n","7                         0.0    51.608487        1.229295   \n","8                         2.0    39.613963        5.527721   \n","9                         0.0    27.917864        1.859001   \n","\n","   YEARS_REGISTRATION  YEARS_ID_PUBLISH  YEARS_LAST_PHONE_CHANGE  \\\n","0            9.987680          5.804244                 3.104723   \n","1            3.247091          0.796715                 2.266940   \n","2           11.663244          6.929500                 2.231348   \n","3           26.921287          6.672142                 1.689254   \n","4           11.802875          9.467488                 3.028063   \n","5           13.607118          1.305955                 6.943190   \n","6            3.321013          1.694730                 4.276523   \n","7           12.585900          6.513347                 2.929500   \n","8           39.526352         10.929500                 4.580424   \n","9           12.120465          2.020534                 2.310746   \n","\n","   PREV_SK_ID_PREV_COUNT  PREV_SK_ID_CURR_FIRST  PREV_AMT_ANNUITY_MEAN  \\\n","0                    1.0               100002.0            9251.775000   \n","1                    3.0               100003.0           56553.990000   \n","2                    1.0               100004.0            5357.250000   \n","3                    9.0               100006.0           21598.390000   \n","4                    6.0               100007.0           12278.805000   \n","5                    5.0               100008.0           17019.603000   \n","6                    7.0               100009.0           10051.412143   \n","7                    1.0               100010.0           27463.410000   \n","8                    4.0               100012.0           11355.423750   \n","9                    2.0               100014.0           12806.550000   \n","\n","   PREV_AMT_ANNUITY_MEDIAN  PREV_AMT_APPLICATION_MEAN  \\\n","0                9251.7750              179055.000000   \n","1               64567.6650              435436.500000   \n","2                5357.2500               24282.000000   \n","3               21739.2300              272203.260000   \n","4               14524.3125              150530.250000   \n","5               17885.8350              155701.800000   \n","6                8996.7600               76741.714286   \n","7               27463.4100              247212.000000   \n","8               10335.1950               60930.000000   \n","9               12806.5500               96536.250000   \n","\n","   PREV_AMT_APPLICATION_MEDIAN  PREV_AMT_CREDIT_MEAN  PREV_AMT_CREDIT_MEDIAN  \\\n","0                    179055.00         179055.000000                179055.0   \n","1                    337500.00         484191.000000                348637.5   \n","2                     24282.00          20106.000000                 20106.0   \n","3                    270000.00         291695.500000                267930.0   \n","4                    191250.00         166638.750000                197932.5   \n","5                    121455.00         162767.700000                109309.5   \n","6                     95841.00          70137.642857                 88614.0   \n","7                    247212.00         260811.000000                260811.0   \n","8                     54360.00          74119.500000                 68985.0   \n","9                     96536.25         102834.000000                102834.0   \n","\n","   PREV_AMT_GOODS_PRICE_MEAN  PREV_AMT_GOODS_PRICE_MEDIAN  \\\n","0              179055.000000                    179055.00   \n","1              435436.500000                    337500.00   \n","2               24282.000000                     24282.00   \n","3              277203.260000                    270000.00   \n","4              150530.250000                    191250.00   \n","5              155701.800000                    121455.00   \n","6               76741.714286                     95841.00   \n","7              247212.000000                    247212.00   \n","8               60930.000000                     54360.00   \n","9               96536.250000                     96536.25   \n","\n","  PREV_NAME_CONTRACT_TYPE_<LAMBDA> PREV_WEEKDAY_APPR_PROCESS_START_<LAMBDA>  \\\n","0                   Consumer loans                                 SATURDAY   \n","1                   Consumer loans                                   FRIDAY   \n","2                   Consumer loans                                   FRIDAY   \n","3                       Cash loans                                 THURSDAY   \n","4                       Cash loans                                   SUNDAY   \n","5                   Consumer loans                                   MONDAY   \n","6                   Consumer loans                                 SATURDAY   \n","7                   Consumer loans                                  TUESDAY   \n","8                       Cash loans                                   FRIDAY   \n","9                   Consumer loans                                  TUESDAY   \n","\n","  PREV_NAME_CASH_LOAN_PURPOSE_<LAMBDA> PREV_NAME_CONTRACT_STATUS_<LAMBDA>  \\\n","0                                  XAP                           Approved   \n","1                                  XAP                           Approved   \n","2                                  XAP                           Approved   \n","3                                  XNA                           Approved   \n","4                                  XNA                           Approved   \n","5                                  XAP                           Approved   \n","6                                  XAP                           Approved   \n","7                                  XAP                           Approved   \n","8                                  XNA                           Approved   \n","9                                  XAP                           Approved   \n","\n","  PREV_NAME_PAYMENT_TYPE_<LAMBDA> PREV_CODE_REJECT_REASON_<LAMBDA>  \\\n","0                             XNA                              XAP   \n","1           Cash through the bank                              XAP   \n","2           Cash through the bank                              XAP   \n","3                             XNA                              XAP   \n","4           Cash through the bank                              XAP   \n","5           Cash through the bank                              XAP   \n","6           Cash through the bank                              XAP   \n","7           Cash through the bank                              XAP   \n","8           Cash through the bank                              XAP   \n","9           Cash through the bank                              XAP   \n","\n","  PREV_NAME_CLIENT_TYPE_<LAMBDA> PREV_NAME_GOODS_CATEGORY_<LAMBDA>  \\\n","0                            New                          Vehicles   \n","1                      Refreshed              Consumer Electronics   \n","2                            New                            Mobile   \n","3                       Repeater                               XNA   \n","4                       Repeater                               XNA   \n","5                       Repeater                               XNA   \n","6                       Repeater                       Audio/Video   \n","7                            New                         Furniture   \n","8                       Repeater                               XNA   \n","9                            New                         Computers   \n","\n","  PREV_NAME_PORTFOLIO_<LAMBDA> PREV_NAME_PRODUCT_TYPE_<LAMBDA>  \\\n","0                          POS                             XNA   \n","1                          POS                             XNA   \n","2                          POS                             XNA   \n","3                         Cash                             XNA   \n","4                         Cash                          x-sell   \n","5                          POS                             XNA   \n","6                          POS                             XNA   \n","7                          POS                             XNA   \n","8                         Cash                             XNA   \n","9                          POS                             XNA   \n","\n","  PREV_CHANNEL_TYPE_<LAMBDA> PREV_NAME_SELLER_INDUSTRY_<LAMBDA>  \\\n","0                      Stone                    Auto technology   \n","1               Country-wide               Consumer electronics   \n","2           Regional / Local                       Connectivity   \n","3    Credit and cash offices                                XNA   \n","4               Country-wide               Consumer electronics   \n","5               Country-wide               Consumer electronics   \n","6           Regional / Local               Consumer electronics   \n","7                      Stone                          Furniture   \n","8    Credit and cash offices                                XNA   \n","9               Country-wide               Consumer electronics   \n","\n","  PREV_NAME_YIELD_GROUP_<LAMBDA> PREV_PRODUCT_COMBINATION_<LAMBDA>  \\\n","0                     low_normal           POS other with interest   \n","1                         middle                  Cash X-Sell: low   \n","2                         middle       POS mobile without interest   \n","3                            XNA                              Cash   \n","4                           high               Cash X-Sell: middle   \n","5                     low_normal       POS household with interest   \n","6                         middle       POS household with interest   \n","7                     low_action     POS industry without interest   \n","8                           high                 Cash X-Sell: high   \n","9                     low_action    POS household without interest   \n","\n","   PREV_NFLAG_LAST_APPL_IN_DAY_MAX  PREV_NFLAG_INSURED_ON_APPROVAL_MAX  \\\n","0                              1.0                                 0.0   \n","1                              1.0                                 1.0   \n","2                              1.0                                 0.0   \n","3                              1.0                                 0.0   \n","4                              1.0                                 1.0   \n","5                              1.0                                 1.0   \n","6                              1.0                                 0.0   \n","7                              1.0                                 0.0   \n","8                              1.0                                 1.0   \n","9                              1.0                                 0.0   \n","\n","   PREV_CNT_PAYMENT_MAX  PREV_HOUR_APPR_PROCESS_START_MEAN  \\\n","0                  24.0                           9.000000   \n","1                  12.0                          14.666667   \n","2                   4.0                           5.000000   \n","3                  48.0                          14.666667   \n","4                  48.0                          12.333333   \n","5                  30.0                          12.000000   \n","6                  12.0                          13.714286   \n","7                  10.0                          16.000000   \n","8                  24.0                          12.500000   \n","9                  12.0                          13.500000   \n","\n","   PREV_SELLERPLACE_AREA_MEAN  PREV_YEARS_DECISION_MEAN  \\\n","0                  500.000000                  1.659138   \n","1                  533.000000                  3.572895   \n","2                   30.000000                  2.231348   \n","3                  894.222222                  0.745912   \n","4                  409.166667                  3.347935   \n","5                   73.000000                  3.263518   \n","6                  170.000000                  1.969297   \n","7                 8636.000000                  2.929500   \n","8                    9.750000                  2.134839   \n","9                  765.000000                  1.295003   \n","\n","   PREV_YEARS_FIRST_DRAWING_MEAN  PREV_YEARS_FIRST_DUE_MEAN  \\\n","0                     999.980835                   1.546886   \n","1                     999.980835                   3.488935   \n","2                     999.980835                   2.146475   \n","3                     889.369534                 112.988364   \n","4                     999.980835                   3.201916   \n","5                     999.980835                   3.586037   \n","6                     999.980835                   1.884424   \n","7                     999.980835                   2.844627   \n","8                     999.980835                   2.553730   \n","9                     999.980835                   1.200548   \n","\n","   PREV_YEARS_LAST_DUE_1ST_VERSION_MEAN  PREV_YEARS_LAST_DUE_MEAN  \\\n","0                              0.342231                  0.068446   \n","1                              2.749715                  2.886607   \n","2                              1.900068                  1.982204   \n","3                            223.303065                334.540726   \n","4                              2.421173                169.078713   \n","5                              2.898836                  3.183573   \n","6                              1.487044                144.252665   \n","7                              2.105407                  2.105407   \n","8                              1.403149                  1.824778   \n","9                              0.778919                500.651608   \n","\n","   PREV_YEARS_TERMINATION_MEAN  TARGET  \n","0                     0.046543       1  \n","1                     2.867442       0  \n","2                     1.954825       0  \n","3                   334.539205       0  \n","4                   169.061373       0  \n","5                     2.449281       0  \n","6                   144.236237       0  \n","7                     2.086242       0  \n","8                     1.820671       0  \n","9                   500.640657       0  "],"text/html":["\n","  <div id=\"df-252b0057-982b-4a76-a43a-794d6eab20b3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SK_ID_CURR</th>\n","      <th>NAME_CONTRACT_TYPE</th>\n","      <th>CODE_GENDER</th>\n","      <th>FLAG_OWN_CAR</th>\n","      <th>FLAG_OWN_REALTY</th>\n","      <th>CNT_CHILDREN</th>\n","      <th>AMT_INCOME_TOTAL</th>\n","      <th>AMT_CREDIT</th>\n","      <th>AMT_ANNUITY</th>\n","      <th>AMT_GOODS_PRICE</th>\n","      <th>NAME_TYPE_SUITE</th>\n","      <th>NAME_INCOME_TYPE</th>\n","      <th>NAME_EDUCATION_TYPE</th>\n","      <th>NAME_FAMILY_STATUS</th>\n","      <th>NAME_HOUSING_TYPE</th>\n","      <th>REGION_POPULATION_RELATIVE</th>\n","      <th>OWN_CAR_AGE</th>\n","      <th>FLAG_MOBIL</th>\n","      <th>FLAG_EMP_PHONE</th>\n","      <th>FLAG_WORK_PHONE</th>\n","      <th>FLAG_CONT_MOBILE</th>\n","      <th>FLAG_PHONE</th>\n","      <th>FLAG_EMAIL</th>\n","      <th>OCCUPATION_TYPE</th>\n","      <th>CNT_FAM_MEMBERS</th>\n","      <th>REGION_RATING_CLIENT</th>\n","      <th>REGION_RATING_CLIENT_W_CITY</th>\n","      <th>WEEKDAY_APPR_PROCESS_START</th>\n","      <th>HOUR_APPR_PROCESS_START</th>\n","      <th>REG_REGION_NOT_LIVE_REGION</th>\n","      <th>REG_REGION_NOT_WORK_REGION</th>\n","      <th>LIVE_REGION_NOT_WORK_REGION</th>\n","      <th>REG_CITY_NOT_LIVE_CITY</th>\n","      <th>REG_CITY_NOT_WORK_CITY</th>\n","      <th>LIVE_CITY_NOT_WORK_CITY</th>\n","      <th>ORGANIZATION_TYPE</th>\n","      <th>EXT_SOURCE_2</th>\n","      <th>EXT_SOURCE_3</th>\n","      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n","      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n","      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n","      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n","      <th>FLAG_DOCUMENT_2</th>\n","      <th>FLAG_DOCUMENT_3</th>\n","      <th>FLAG_DOCUMENT_4</th>\n","      <th>FLAG_DOCUMENT_5</th>\n","      <th>FLAG_DOCUMENT_6</th>\n","      <th>FLAG_DOCUMENT_7</th>\n","      <th>FLAG_DOCUMENT_8</th>\n","      <th>FLAG_DOCUMENT_9</th>\n","      <th>FLAG_DOCUMENT_10</th>\n","      <th>FLAG_DOCUMENT_11</th>\n","      <th>FLAG_DOCUMENT_12</th>\n","      <th>FLAG_DOCUMENT_13</th>\n","      <th>FLAG_DOCUMENT_14</th>\n","      <th>FLAG_DOCUMENT_15</th>\n","      <th>FLAG_DOCUMENT_16</th>\n","      <th>FLAG_DOCUMENT_17</th>\n","      <th>FLAG_DOCUMENT_18</th>\n","      <th>FLAG_DOCUMENT_19</th>\n","      <th>FLAG_DOCUMENT_20</th>\n","      <th>FLAG_DOCUMENT_21</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n","      <th>YEARS_BIRTH</th>\n","      <th>YEARS_EMPLOYED</th>\n","      <th>YEARS_REGISTRATION</th>\n","      <th>YEARS_ID_PUBLISH</th>\n","      <th>YEARS_LAST_PHONE_CHANGE</th>\n","      <th>PREV_SK_ID_PREV_COUNT</th>\n","      <th>PREV_SK_ID_CURR_FIRST</th>\n","      <th>PREV_AMT_ANNUITY_MEAN</th>\n","      <th>PREV_AMT_ANNUITY_MEDIAN</th>\n","      <th>PREV_AMT_APPLICATION_MEAN</th>\n","      <th>PREV_AMT_APPLICATION_MEDIAN</th>\n","      <th>PREV_AMT_CREDIT_MEAN</th>\n","      <th>PREV_AMT_CREDIT_MEDIAN</th>\n","      <th>PREV_AMT_GOODS_PRICE_MEAN</th>\n","      <th>PREV_AMT_GOODS_PRICE_MEDIAN</th>\n","      <th>PREV_NAME_CONTRACT_TYPE_&lt;LAMBDA&gt;</th>\n","      <th>PREV_WEEKDAY_APPR_PROCESS_START_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_CASH_LOAN_PURPOSE_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_CONTRACT_STATUS_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_PAYMENT_TYPE_&lt;LAMBDA&gt;</th>\n","      <th>PREV_CODE_REJECT_REASON_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_CLIENT_TYPE_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_GOODS_CATEGORY_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_PORTFOLIO_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_PRODUCT_TYPE_&lt;LAMBDA&gt;</th>\n","      <th>PREV_CHANNEL_TYPE_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_SELLER_INDUSTRY_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NAME_YIELD_GROUP_&lt;LAMBDA&gt;</th>\n","      <th>PREV_PRODUCT_COMBINATION_&lt;LAMBDA&gt;</th>\n","      <th>PREV_NFLAG_LAST_APPL_IN_DAY_MAX</th>\n","      <th>PREV_NFLAG_INSURED_ON_APPROVAL_MAX</th>\n","      <th>PREV_CNT_PAYMENT_MAX</th>\n","      <th>PREV_HOUR_APPR_PROCESS_START_MEAN</th>\n","      <th>PREV_SELLERPLACE_AREA_MEAN</th>\n","      <th>PREV_YEARS_DECISION_MEAN</th>\n","      <th>PREV_YEARS_FIRST_DRAWING_MEAN</th>\n","      <th>PREV_YEARS_FIRST_DUE_MEAN</th>\n","      <th>PREV_YEARS_LAST_DUE_1ST_VERSION_MEAN</th>\n","      <th>PREV_YEARS_LAST_DUE_MEAN</th>\n","      <th>PREV_YEARS_TERMINATION_MEAN</th>\n","      <th>TARGET</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100002</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>202500.0</td>\n","      <td>406597.5</td>\n","      <td>24700.5</td>\n","      <td>351000.0</td>\n","      <td>Unaccompanied</td>\n","      <td>Working</td>\n","      <td>Secondary / secondary special</td>\n","      <td>Single / not married</td>\n","      <td>House / apartment</td>\n","      <td>0.018801</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Laborers</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>WEDNESDAY</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Business Entity Type 3</td>\n","      <td>0.262949</td>\n","      <td>0.139376</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>25.902806</td>\n","      <td>1.744011</td>\n","      <td>9.987680</td>\n","      <td>5.804244</td>\n","      <td>3.104723</td>\n","      <td>1.0</td>\n","      <td>100002.0</td>\n","      <td>9251.775000</td>\n","      <td>9251.7750</td>\n","      <td>179055.000000</td>\n","      <td>179055.00</td>\n","      <td>179055.000000</td>\n","      <td>179055.0</td>\n","      <td>179055.000000</td>\n","      <td>179055.00</td>\n","      <td>Consumer loans</td>\n","      <td>SATURDAY</td>\n","      <td>XAP</td>\n","      <td>Approved</td>\n","      <td>XNA</td>\n","      <td>XAP</td>\n","      <td>New</td>\n","      <td>Vehicles</td>\n","      <td>POS</td>\n","      <td>XNA</td>\n","      <td>Stone</td>\n","      <td>Auto technology</td>\n","      <td>low_normal</td>\n","      <td>POS other with interest</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>24.0</td>\n","      <td>9.000000</td>\n","      <td>500.000000</td>\n","      <td>1.659138</td>\n","      <td>999.980835</td>\n","      <td>1.546886</td>\n","      <td>0.342231</td>\n","      <td>0.068446</td>\n","      <td>0.046543</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100003</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0</td>\n","      <td>270000.0</td>\n","      <td>1293502.5</td>\n","      <td>35698.5</td>\n","      <td>1129500.0</td>\n","      <td>Family</td>\n","      <td>State servant</td>\n","      <td>Higher education</td>\n","      <td>Married</td>\n","      <td>House / apartment</td>\n","      <td>0.003541</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Core staff</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>MONDAY</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>School</td>\n","      <td>0.622246</td>\n","      <td>0.544235</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>45.900068</td>\n","      <td>3.252567</td>\n","      <td>3.247091</td>\n","      <td>0.796715</td>\n","      <td>2.266940</td>\n","      <td>3.0</td>\n","      <td>100003.0</td>\n","      <td>56553.990000</td>\n","      <td>64567.6650</td>\n","      <td>435436.500000</td>\n","      <td>337500.00</td>\n","      <td>484191.000000</td>\n","      <td>348637.5</td>\n","      <td>435436.500000</td>\n","      <td>337500.00</td>\n","      <td>Consumer loans</td>\n","      <td>FRIDAY</td>\n","      <td>XAP</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>Refreshed</td>\n","      <td>Consumer Electronics</td>\n","      <td>POS</td>\n","      <td>XNA</td>\n","      <td>Country-wide</td>\n","      <td>Consumer electronics</td>\n","      <td>middle</td>\n","      <td>Cash X-Sell: low</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>12.0</td>\n","      <td>14.666667</td>\n","      <td>533.000000</td>\n","      <td>3.572895</td>\n","      <td>999.980835</td>\n","      <td>3.488935</td>\n","      <td>2.749715</td>\n","      <td>2.886607</td>\n","      <td>2.867442</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100004</td>\n","      <td>Revolving loans</td>\n","      <td>M</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>67500.0</td>\n","      <td>135000.0</td>\n","      <td>6750.0</td>\n","      <td>135000.0</td>\n","      <td>Unaccompanied</td>\n","      <td>Working</td>\n","      <td>Secondary / secondary special</td>\n","      <td>Single / not married</td>\n","      <td>House / apartment</td>\n","      <td>0.010032</td>\n","      <td>26.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Laborers</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>MONDAY</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Government</td>\n","      <td>0.555912</td>\n","      <td>0.729567</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>52.145106</td>\n","      <td>0.616016</td>\n","      <td>11.663244</td>\n","      <td>6.929500</td>\n","      <td>2.231348</td>\n","      <td>1.0</td>\n","      <td>100004.0</td>\n","      <td>5357.250000</td>\n","      <td>5357.2500</td>\n","      <td>24282.000000</td>\n","      <td>24282.00</td>\n","      <td>20106.000000</td>\n","      <td>20106.0</td>\n","      <td>24282.000000</td>\n","      <td>24282.00</td>\n","      <td>Consumer loans</td>\n","      <td>FRIDAY</td>\n","      <td>XAP</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>New</td>\n","      <td>Mobile</td>\n","      <td>POS</td>\n","      <td>XNA</td>\n","      <td>Regional / Local</td>\n","      <td>Connectivity</td>\n","      <td>middle</td>\n","      <td>POS mobile without interest</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>5.000000</td>\n","      <td>30.000000</td>\n","      <td>2.231348</td>\n","      <td>999.980835</td>\n","      <td>2.146475</td>\n","      <td>1.900068</td>\n","      <td>1.982204</td>\n","      <td>1.954825</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100006</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>135000.0</td>\n","      <td>312682.5</td>\n","      <td>29686.5</td>\n","      <td>297000.0</td>\n","      <td>Unaccompanied</td>\n","      <td>Working</td>\n","      <td>Secondary / secondary special</td>\n","      <td>Civil marriage</td>\n","      <td>House / apartment</td>\n","      <td>0.008019</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Laborers</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>WEDNESDAY</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Business Entity Type 3</td>\n","      <td>0.650442</td>\n","      <td>0.515495</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>52.032854</td>\n","      <td>8.320329</td>\n","      <td>26.921287</td>\n","      <td>6.672142</td>\n","      <td>1.689254</td>\n","      <td>9.0</td>\n","      <td>100006.0</td>\n","      <td>21598.390000</td>\n","      <td>21739.2300</td>\n","      <td>272203.260000</td>\n","      <td>270000.00</td>\n","      <td>291695.500000</td>\n","      <td>267930.0</td>\n","      <td>277203.260000</td>\n","      <td>270000.00</td>\n","      <td>Cash loans</td>\n","      <td>THURSDAY</td>\n","      <td>XNA</td>\n","      <td>Approved</td>\n","      <td>XNA</td>\n","      <td>XAP</td>\n","      <td>Repeater</td>\n","      <td>XNA</td>\n","      <td>Cash</td>\n","      <td>XNA</td>\n","      <td>Credit and cash offices</td>\n","      <td>XNA</td>\n","      <td>XNA</td>\n","      <td>Cash</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>48.0</td>\n","      <td>14.666667</td>\n","      <td>894.222222</td>\n","      <td>0.745912</td>\n","      <td>889.369534</td>\n","      <td>112.988364</td>\n","      <td>223.303065</td>\n","      <td>334.540726</td>\n","      <td>334.539205</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>100007</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>121500.0</td>\n","      <td>513000.0</td>\n","      <td>21865.5</td>\n","      <td>513000.0</td>\n","      <td>Unaccompanied</td>\n","      <td>Working</td>\n","      <td>Secondary / secondary special</td>\n","      <td>Single / not married</td>\n","      <td>House / apartment</td>\n","      <td>0.028663</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Core staff</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>THURSDAY</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Religion</td>\n","      <td>0.322738</td>\n","      <td>0.492060</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>54.570842</td>\n","      <td>8.317591</td>\n","      <td>11.802875</td>\n","      <td>9.467488</td>\n","      <td>3.028063</td>\n","      <td>6.0</td>\n","      <td>100007.0</td>\n","      <td>12278.805000</td>\n","      <td>14524.3125</td>\n","      <td>150530.250000</td>\n","      <td>191250.00</td>\n","      <td>166638.750000</td>\n","      <td>197932.5</td>\n","      <td>150530.250000</td>\n","      <td>191250.00</td>\n","      <td>Cash loans</td>\n","      <td>SUNDAY</td>\n","      <td>XNA</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>Repeater</td>\n","      <td>XNA</td>\n","      <td>Cash</td>\n","      <td>x-sell</td>\n","      <td>Country-wide</td>\n","      <td>Consumer electronics</td>\n","      <td>high</td>\n","      <td>Cash X-Sell: middle</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>48.0</td>\n","      <td>12.333333</td>\n","      <td>409.166667</td>\n","      <td>3.347935</td>\n","      <td>999.980835</td>\n","      <td>3.201916</td>\n","      <td>2.421173</td>\n","      <td>169.078713</td>\n","      <td>169.061373</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>100008</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>99000.0</td>\n","      <td>490495.5</td>\n","      <td>27517.5</td>\n","      <td>454500.0</td>\n","      <td>Spouse, partner</td>\n","      <td>State servant</td>\n","      <td>Secondary / secondary special</td>\n","      <td>Married</td>\n","      <td>House / apartment</td>\n","      <td>0.035792</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Laborers</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>WEDNESDAY</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Other</td>\n","      <td>0.354225</td>\n","      <td>0.621226</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>46.381930</td>\n","      <td>4.347707</td>\n","      <td>13.607118</td>\n","      <td>1.305955</td>\n","      <td>6.943190</td>\n","      <td>5.0</td>\n","      <td>100008.0</td>\n","      <td>17019.603000</td>\n","      <td>17885.8350</td>\n","      <td>155701.800000</td>\n","      <td>121455.00</td>\n","      <td>162767.700000</td>\n","      <td>109309.5</td>\n","      <td>155701.800000</td>\n","      <td>121455.00</td>\n","      <td>Consumer loans</td>\n","      <td>MONDAY</td>\n","      <td>XAP</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>Repeater</td>\n","      <td>XNA</td>\n","      <td>POS</td>\n","      <td>XNA</td>\n","      <td>Country-wide</td>\n","      <td>Consumer electronics</td>\n","      <td>low_normal</td>\n","      <td>POS household with interest</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>30.0</td>\n","      <td>12.000000</td>\n","      <td>73.000000</td>\n","      <td>3.263518</td>\n","      <td>999.980835</td>\n","      <td>3.586037</td>\n","      <td>2.898836</td>\n","      <td>3.183573</td>\n","      <td>2.449281</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>100009</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>1</td>\n","      <td>171000.0</td>\n","      <td>1560726.0</td>\n","      <td>41301.0</td>\n","      <td>1395000.0</td>\n","      <td>Unaccompanied</td>\n","      <td>Commercial associate</td>\n","      <td>Higher education</td>\n","      <td>Married</td>\n","      <td>House / apartment</td>\n","      <td>0.035792</td>\n","      <td>17.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Accountants</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>SUNDAY</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Business Entity Type 3</td>\n","      <td>0.724000</td>\n","      <td>0.492060</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>37.722108</td>\n","      <td>8.569473</td>\n","      <td>3.321013</td>\n","      <td>1.694730</td>\n","      <td>4.276523</td>\n","      <td>7.0</td>\n","      <td>100009.0</td>\n","      <td>10051.412143</td>\n","      <td>8996.7600</td>\n","      <td>76741.714286</td>\n","      <td>95841.00</td>\n","      <td>70137.642857</td>\n","      <td>88614.0</td>\n","      <td>76741.714286</td>\n","      <td>95841.00</td>\n","      <td>Consumer loans</td>\n","      <td>SATURDAY</td>\n","      <td>XAP</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>Repeater</td>\n","      <td>Audio/Video</td>\n","      <td>POS</td>\n","      <td>XNA</td>\n","      <td>Regional / Local</td>\n","      <td>Consumer electronics</td>\n","      <td>middle</td>\n","      <td>POS household with interest</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>13.714286</td>\n","      <td>170.000000</td>\n","      <td>1.969297</td>\n","      <td>999.980835</td>\n","      <td>1.884424</td>\n","      <td>1.487044</td>\n","      <td>144.252665</td>\n","      <td>144.236237</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>100010</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>360000.0</td>\n","      <td>1530000.0</td>\n","      <td>42075.0</td>\n","      <td>1530000.0</td>\n","      <td>Unaccompanied</td>\n","      <td>State servant</td>\n","      <td>Higher education</td>\n","      <td>Married</td>\n","      <td>House / apartment</td>\n","      <td>0.003122</td>\n","      <td>8.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Managers</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>MONDAY</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Other</td>\n","      <td>0.714279</td>\n","      <td>0.540654</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.608487</td>\n","      <td>1.229295</td>\n","      <td>12.585900</td>\n","      <td>6.513347</td>\n","      <td>2.929500</td>\n","      <td>1.0</td>\n","      <td>100010.0</td>\n","      <td>27463.410000</td>\n","      <td>27463.4100</td>\n","      <td>247212.000000</td>\n","      <td>247212.00</td>\n","      <td>260811.000000</td>\n","      <td>260811.0</td>\n","      <td>247212.000000</td>\n","      <td>247212.00</td>\n","      <td>Consumer loans</td>\n","      <td>TUESDAY</td>\n","      <td>XAP</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>New</td>\n","      <td>Furniture</td>\n","      <td>POS</td>\n","      <td>XNA</td>\n","      <td>Stone</td>\n","      <td>Furniture</td>\n","      <td>low_action</td>\n","      <td>POS industry without interest</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>16.000000</td>\n","      <td>8636.000000</td>\n","      <td>2.929500</td>\n","      <td>999.980835</td>\n","      <td>2.844627</td>\n","      <td>2.105407</td>\n","      <td>2.105407</td>\n","      <td>2.086242</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>100012</td>\n","      <td>Revolving loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>135000.0</td>\n","      <td>405000.0</td>\n","      <td>20250.0</td>\n","      <td>405000.0</td>\n","      <td>Unaccompanied</td>\n","      <td>Working</td>\n","      <td>Secondary / secondary special</td>\n","      <td>Single / not married</td>\n","      <td>House / apartment</td>\n","      <td>0.019689</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Laborers</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>THURSDAY</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Electricity</td>\n","      <td>0.746644</td>\n","      <td>0.492060</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>39.613963</td>\n","      <td>5.527721</td>\n","      <td>39.526352</td>\n","      <td>10.929500</td>\n","      <td>4.580424</td>\n","      <td>4.0</td>\n","      <td>100012.0</td>\n","      <td>11355.423750</td>\n","      <td>10335.1950</td>\n","      <td>60930.000000</td>\n","      <td>54360.00</td>\n","      <td>74119.500000</td>\n","      <td>68985.0</td>\n","      <td>60930.000000</td>\n","      <td>54360.00</td>\n","      <td>Cash loans</td>\n","      <td>FRIDAY</td>\n","      <td>XNA</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>Repeater</td>\n","      <td>XNA</td>\n","      <td>Cash</td>\n","      <td>XNA</td>\n","      <td>Credit and cash offices</td>\n","      <td>XNA</td>\n","      <td>high</td>\n","      <td>Cash X-Sell: high</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>24.0</td>\n","      <td>12.500000</td>\n","      <td>9.750000</td>\n","      <td>2.134839</td>\n","      <td>999.980835</td>\n","      <td>2.553730</td>\n","      <td>1.403149</td>\n","      <td>1.824778</td>\n","      <td>1.820671</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>100014</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>1</td>\n","      <td>112500.0</td>\n","      <td>652500.0</td>\n","      <td>21177.0</td>\n","      <td>652500.0</td>\n","      <td>Unaccompanied</td>\n","      <td>Working</td>\n","      <td>Higher education</td>\n","      <td>Married</td>\n","      <td>House / apartment</td>\n","      <td>0.022800</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Core staff</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>SATURDAY</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Medicine</td>\n","      <td>0.651862</td>\n","      <td>0.363945</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>27.917864</td>\n","      <td>1.859001</td>\n","      <td>12.120465</td>\n","      <td>2.020534</td>\n","      <td>2.310746</td>\n","      <td>2.0</td>\n","      <td>100014.0</td>\n","      <td>12806.550000</td>\n","      <td>12806.5500</td>\n","      <td>96536.250000</td>\n","      <td>96536.25</td>\n","      <td>102834.000000</td>\n","      <td>102834.0</td>\n","      <td>96536.250000</td>\n","      <td>96536.25</td>\n","      <td>Consumer loans</td>\n","      <td>TUESDAY</td>\n","      <td>XAP</td>\n","      <td>Approved</td>\n","      <td>Cash through the bank</td>\n","      <td>XAP</td>\n","      <td>New</td>\n","      <td>Computers</td>\n","      <td>POS</td>\n","      <td>XNA</td>\n","      <td>Country-wide</td>\n","      <td>Consumer electronics</td>\n","      <td>low_action</td>\n","      <td>POS household without interest</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>13.500000</td>\n","      <td>765.000000</td>\n","      <td>1.295003</td>\n","      <td>999.980835</td>\n","      <td>1.200548</td>\n","      <td>0.778919</td>\n","      <td>500.651608</td>\n","      <td>500.640657</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-252b0057-982b-4a76-a43a-794d6eab20b3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-252b0057-982b-4a76-a43a-794d6eab20b3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-252b0057-982b-4a76-a43a-794d6eab20b3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-76942263-cb4c-44cd-8bf9-2143f52fd9f1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76942263-cb4c-44cd-8bf9-2143f52fd9f1')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-76942263-cb4c-44cd-8bf9-2143f52fd9f1 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_main"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["X = df_main.drop('TARGET', axis=1)\n","y = df_main['TARGET']"],"metadata":{"id":"g9j5Hfe6MQfn","executionInfo":{"status":"ok","timestamp":1764004900422,"user_tz":-120,"elapsed":30,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n","cat_indices = [X.columns.get_loc(col) for col in cat_cols]\n","\n","for col in cat_cols:\n","    X[col] = X[col].astype('category')"],"metadata":{"id":"3oEeqAiRMReY","executionInfo":{"status":"ok","timestamp":1764004900842,"user_tz":-120,"elapsed":417,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["lgb_model = LGBMClassifier(\n","    objective='binary',\n","    random_state=42,\n","    n_jobs=-1,\n","    n_estimators=500\n",")\n"],"metadata":{"id":"nQx712_BMX5y","executionInfo":{"status":"ok","timestamp":1764004900845,"user_tz":-120,"elapsed":1,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["param_dist = {\n","    'num_leaves': [31, 50, 70],\n","    'max_depth': [-1, 10, 20, 30],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'subsample': [0.6, 0.8, 1.0],\n","    'colsample_bytree': [0.6, 0.8, 1.0],\n","    'reg_alpha': [0, 0.1, 0.5],\n","    'reg_lambda': [0, 0.1, 0.5]\n","}"],"metadata":{"id":"S0u78OtANP_-","executionInfo":{"status":"ok","timestamp":1764004900861,"user_tz":-120,"elapsed":2,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)"],"metadata":{"id":"80z5SHPCNoHB","executionInfo":{"status":"ok","timestamp":1764004900868,"user_tz":-120,"elapsed":4,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["scorer = make_scorer(f1_score)"],"metadata":{"id":"r_yd7WNwNrJ3","executionInfo":{"status":"ok","timestamp":1764004900873,"user_tz":-120,"elapsed":2,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["rs_cv = RandomizedSearchCV(\n","    estimator=lgb_model,\n","    param_distributions=param_dist,\n","    n_iter=50,\n","    scoring=scorer,\n","    cv=skf,\n","    verbose=2,\n","    random_state=42\n",")\n"],"metadata":{"id":"ACrvPy7oNvpN","executionInfo":{"status":"ok","timestamp":1764004900886,"user_tz":-120,"elapsed":2,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["rs_cv.fit(X, y, categorical_feature=cat_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ql8rKGGlQodr","outputId":"7efa6f59-2dfa-4878-ba96-6258e56f54d7","executionInfo":{"status":"ok","timestamp":1764013016277,"user_tz":-120,"elapsed":8115389,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 4 folds for each of 50 candidates, totalling 200 fits\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099443 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  50.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097813 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  50.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098076 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  50.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100149 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  52.0s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207036 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0.5, subsample=0.6; total time=  47.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.199026 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0.5, subsample=0.6; total time=  55.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.253170 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0.5, subsample=0.6; total time=  50.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096693 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0.5, subsample=0.6; total time=  52.8s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099516 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  33.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103098 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  32.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103094 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  31.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103666 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  33.1s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099428 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  52.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101629 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  50.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101945 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  51.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099923 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  49.6s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107535 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  25.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095853 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  25.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098809 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  25.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224586 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  25.9s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090251 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=  49.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087117 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=  46.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088333 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=  45.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090708 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=  47.3s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.174312 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=1.0; total time=  35.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102063 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=1.0; total time=  36.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114042 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=1.0; total time=  34.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098742 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=1.0; total time=  35.7s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088125 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  41.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101368 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  40.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087601 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  40.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088870 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  41.2s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098755 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  36.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099190 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  35.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104160 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  36.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100791 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  36.9s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103312 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  40.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111398 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  39.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098378 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  38.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099994 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  39.8s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221660 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  30.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228973 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  29.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219237 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  31.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099716 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  33.6s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.222793 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=1.0; total time=  55.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113480 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=1.0; total time=  53.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099061 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=1.0; total time=  56.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096234 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=1.0; total time=  54.2s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086381 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  34.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089371 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  35.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104747 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  35.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089182 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  37.2s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089918 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  37.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092941 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  36.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088430 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  37.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090366 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  37.5s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102407 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  25.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168347 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  25.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115368 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  25.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101584 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  27.5s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092054 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  44.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.176863 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  45.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089377 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  45.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092738 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  45.7s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099471 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  31.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120882 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  30.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100016 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  31.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.231332 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=0.8; total time=  33.6s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101231 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  34.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098776 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  33.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100504 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  34.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.328198 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  38.4s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087104 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  42.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087399 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  42.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125115 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  42.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100538 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  42.3s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.360067 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  30.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101543 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  29.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185040 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  31.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101807 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  30.7s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159906 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  29.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215506 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  28.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096811 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  30.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098548 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  28.5s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087453 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  33.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088920 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  33.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.175335 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  33.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089668 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  34.3s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098649 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  34.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098065 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  32.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168666 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  35.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102412 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  35.6s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114536 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  38.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.189636 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  39.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103159 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  39.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100702 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  39.1s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100223 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=1.0; total time=  30.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.240547 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=1.0; total time=  30.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100857 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=1.0; total time=  33.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100292 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=1.0; total time=  30.2s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101222 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  25.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101401 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  25.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096283 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  25.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.202245 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  25.8s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086407 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  52.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089719 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  54.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090514 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  57.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088343 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  54.1s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.167920 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  33.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215721 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  30.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097876 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  31.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230754 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=30, num_leaves=31, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  30.4s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095864 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  32.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214807 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  33.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095181 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  32.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097906 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=  32.8s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111850 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  49.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100432 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  49.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178083 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  49.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.176295 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.6; total time=  48.9s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.256898 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6; total time=  36.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178868 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6; total time=  37.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.220514 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6; total time=  38.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101660 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.1, reg_lambda=0.1, subsample=0.6; total time=  39.6s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103667 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  31.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154309 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  32.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089927 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  33.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089402 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.8; total time=  31.7s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.165222 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  41.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098090 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  40.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088361 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  41.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086730 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, num_leaves=70, reg_alpha=0.5, reg_lambda=0, subsample=0.8; total time=  41.8s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097351 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  43.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105206 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  44.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118845 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  41.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399139 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  45.8s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099437 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  42.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.370881 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  39.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103989 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  38.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102823 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0, subsample=0.6; total time=  43.1s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101637 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  45.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109412 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  44.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102753 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  44.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116521 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=20, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8; total time=  44.0s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101938 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  41.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.264453 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  38.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104188 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  44.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099950 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=1.0; total time=  43.2s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223881 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=1.0; total time=  47.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098880 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=1.0; total time=  54.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100060 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=1.0; total time= 1.0min\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099998 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.5, subsample=1.0; total time= 1.1min\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112764 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  34.8s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104194 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  33.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110881 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  34.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.260146 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  33.1s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262738 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  37.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.268782 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  39.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.252024 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  36.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.246112 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=-1, num_leaves=31, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  34.7s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.170089 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  42.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108474 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  40.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122136 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  40.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108796 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  41.5s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104056 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  57.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101704 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  57.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113752 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  58.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.360651 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=30, num_leaves=50, reg_alpha=0.1, reg_lambda=0.5, subsample=0.8; total time=  59.7s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103986 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  57.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090283 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  58.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088990 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time= 1.0min\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092906 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time= 1.0min\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.254847 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  41.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105187 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  43.1s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104015 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  46.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111321 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0; total time=  44.5s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.177863 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  49.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146201 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  45.0s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089468 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  47.7s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091374 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=50, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  45.3s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.165786 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  41.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121962 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  43.3s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126187 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  42.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140438 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=20, num_leaves=70, reg_alpha=0, reg_lambda=0.5, subsample=1.0; total time=  42.4s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.232772 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time= 1.0min\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.264211 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time= 1.0min\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.241694 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time= 1.0min\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.246814 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  59.1s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.397316 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  42.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092448 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  40.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093025 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  40.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096732 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=20, num_leaves=50, reg_alpha=0.5, reg_lambda=0.1, subsample=0.6; total time=  37.5s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105318 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  41.4s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087679 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  40.9s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088119 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  40.6s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126949 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=-1, num_leaves=70, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  40.8s\n","[LightGBM] [Info] Number of positive: 109974, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087969 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247443, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  30.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088607 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  31.5s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089754 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11840\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  30.2s\n","[LightGBM] [Info] Number of positive: 109975, number of negative: 137469\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.296975 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11837\n","[LightGBM] [Info] Number of data points in the train set: 247444, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223145\n","[LightGBM] [Info] Start training from score -0.223145\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=-1, num_leaves=31, reg_alpha=0, reg_lambda=0.1, subsample=0.6; total time=  31.4s\n","[LightGBM] [Info] Number of positive: 146633, number of negative: 183292\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.273248 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 11842\n","[LightGBM] [Info] Number of data points in the train set: 329925, number of used features: 103\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444443 -> initscore=-0.223148\n","[LightGBM] [Info] Start training from score -0.223148\n"]},{"output_type":"execute_result","data":{"text/plain":["RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True),\n","                   estimator=LGBMClassifier(n_estimators=500, n_jobs=-1,\n","                                            objective='binary',\n","                                            random_state=42),\n","                   n_iter=50,\n","                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n","                                        'learning_rate': [0.01, 0.05, 0.1],\n","                                        'max_depth': [-1, 10, 20, 30],\n","                                        'num_leaves': [31, 50, 70],\n","                                        'reg_alpha': [0, 0.1, 0.5],\n","                                        'reg_lambda': [0, 0.1, 0.5],\n","                                        'subsample': [0.6, 0.8, 1.0]},\n","                   random_state=42,\n","                   scoring=make_scorer(f1_score, response_method='predict'),\n","                   verbose=2)"],"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: #000;\n","  --sklearn-color-text-muted: #666;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: flex;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","  align-items: start;\n","  justify-content: space-between;\n","  gap: 0.5em;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label .caption {\n","  font-size: 0.6rem;\n","  font-weight: lighter;\n","  color: var(--sklearn-color-text-muted);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 0.5em;\n","  text-align: center;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True),\n","                   estimator=LGBMClassifier(n_estimators=500, n_jobs=-1,\n","                                            objective=&#x27;binary&#x27;,\n","                                            random_state=42),\n","                   n_iter=50,\n","                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n","                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n","                                        &#x27;max_depth&#x27;: [-1, 10, 20, 30],\n","                                        &#x27;num_leaves&#x27;: [31, 50, 70],\n","                                        &#x27;reg_alpha&#x27;: [0, 0.1, 0.5],\n","                                        &#x27;reg_lambda&#x27;: [0, 0.1, 0.5],\n","                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n","                   random_state=42,\n","                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n","                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True),\n","                   estimator=LGBMClassifier(n_estimators=500, n_jobs=-1,\n","                                            objective=&#x27;binary&#x27;,\n","                                            random_state=42),\n","                   n_iter=50,\n","                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n","                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n","                                        &#x27;max_depth&#x27;: [-1, 10, 20, 30],\n","                                        &#x27;num_leaves&#x27;: [31, 50, 70],\n","                                        &#x27;reg_alpha&#x27;: [0, 0.1, 0.5],\n","                                        &#x27;reg_lambda&#x27;: [0, 0.1, 0.5],\n","                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n","                   random_state=42,\n","                   scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n","                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.8, max_depth=20, n_estimators=500, n_jobs=-1,\n","               num_leaves=70, objective=&#x27;binary&#x27;, random_state=42,\n","               reg_alpha=0.5, reg_lambda=0.5, subsample=0.6)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.8, max_depth=20, n_estimators=500, n_jobs=-1,\n","               num_leaves=70, objective=&#x27;binary&#x27;, random_state=42,\n","               reg_alpha=0.5, reg_lambda=0.5, subsample=0.6)</pre></div> </div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["print(\"\\nBest F1 score:\", rs_cv.best_score_)\n","print(\"Best parameters:\", rs_cv.best_params_)"],"metadata":{"id":"WhyWJR88Qq_6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764013016297,"user_tz":-120,"elapsed":16,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"24ca32ea-e404-4dfd-959d-0d9aabbfe4b7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Best F1 score: 0.9341121967396442\n","Best parameters: {'subsample': 0.6, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'num_leaves': 70, 'max_depth': 20, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HdMTfMoUR927","executionInfo":{"status":"ok","timestamp":1764013016301,"user_tz":-120,"elapsed":2,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.2,\n","    stratify=y,\n","    random_state=42\n",")"],"metadata":{"id":"a0FDyBmjsjLB","executionInfo":{"status":"ok","timestamp":1764013016524,"user_tz":-120,"elapsed":219,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["final_model = LGBMClassifier(\n","    objective='binary',\n","    random_state=42,\n","    n_jobs=-1,\n","    n_estimators=500,\n","    **rs_cv.best_params_\n",")"],"metadata":{"id":"FRkCF6ZFTdeK","executionInfo":{"status":"ok","timestamp":1764013016528,"user_tz":-120,"elapsed":2,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["final_model.fit(X_train, y_train, categorical_feature=cat_cols)"],"metadata":{"id":"J9lL5bEDTpTv","colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"status":"ok","timestamp":1764013045318,"user_tz":-120,"elapsed":28785,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"93f6662c-ff31-4904-9d19-7a115c2b6ed4"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 117306, number of negative: 146634\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101527 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 11839\n","[LightGBM] [Info] Number of data points in the train set: 263940, number of used features: 102\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444442 -> initscore=-0.223154\n","[LightGBM] [Info] Start training from score -0.223154\n"]},{"output_type":"execute_result","data":{"text/plain":["LGBMClassifier(colsample_bytree=0.8, max_depth=20, n_estimators=500, n_jobs=-1,\n","               num_leaves=70, objective='binary', random_state=42,\n","               reg_alpha=0.5, reg_lambda=0.5, subsample=0.6)"],"text/html":["<style>#sk-container-id-2 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: #000;\n","  --sklearn-color-text-muted: #666;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-2 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-2 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-2 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-2 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-2 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-2 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-2 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-2 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: flex;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","  align-items: start;\n","  justify-content: space-between;\n","  gap: 0.5em;\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label .caption {\n","  font-size: 0.6rem;\n","  font-weight: lighter;\n","  color: var(--sklearn-color-text-muted);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-2 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-2 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-2 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-2 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-2 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-2 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 0.5em;\n","  text-align: center;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-2 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-2 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.8, max_depth=20, n_estimators=500, n_jobs=-1,\n","               num_leaves=70, objective=&#x27;binary&#x27;, random_state=42,\n","               reg_alpha=0.5, reg_lambda=0.5, subsample=0.6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.8, max_depth=20, n_estimators=500, n_jobs=-1,\n","               num_leaves=70, objective=&#x27;binary&#x27;, random_state=42,\n","               reg_alpha=0.5, reg_lambda=0.5, subsample=0.6)</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["feat_importances = pd.Series(final_model.feature_importances_, index=X.columns)\n","feat_importances.nlargest(20).sort_values().plot(kind='barh', figsize=(10,6))\n","plt.title(\"Top 20 Feature Importances\")\n","plt.show()\n"],"metadata":{"id":"oeNynuFCTqr4","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1764013046379,"user_tz":-120,"elapsed":1065,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"b909a42b-733f-4c95-8868-54b6c96df7d5"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["y_pred = final_model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTbV-34XspTu","executionInfo":{"status":"ok","timestamp":1764013049232,"user_tz":-120,"elapsed":2852,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"7b64fe0c-3cc1-40a9-9ca1-f1798d6f036f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      0.99      0.95     36658\n","           1       0.99      0.88      0.93     29327\n","\n","    accuracy                           0.94     65985\n","   macro avg       0.95      0.94      0.94     65985\n","weighted avg       0.95      0.94      0.94     65985\n","\n"]}]},{"cell_type":"code","source":["print(accuracy_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfsJjvFFhKXS","executionInfo":{"status":"ok","timestamp":1764013049245,"user_tz":-120,"elapsed":11,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"c51fcaa1-38eb-4c6d-fd20-2d4f1edda7b3"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9447298628476168\n"]}]},{"cell_type":"code","source":["cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\\n\", cm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Q1uVsj9ittt","executionInfo":{"status":"ok","timestamp":1764013049257,"user_tz":-120,"elapsed":10,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"410d029b-a74f-469c-dcb4-b5fd7d609294"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[36454   204]\n"," [ 3443 25884]]\n"]}]},{"cell_type":"code","source":["y_prob = final_model.predict_proba(X_test)[:, 1]\n","roc_auc = roc_auc_score(y_test, y_prob)\n","print(\"ROC AUC Score:\", roc_auc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZACVr58VjP3i","executionInfo":{"status":"ok","timestamp":1764013051348,"user_tz":-120,"elapsed":2088,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"7b4e3b6d-1bff-4e31-af73-7c20afbb55b6"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["ROC AUC Score: 0.9700875896946709\n"]}]},{"cell_type":"code","source":["joblib.dump(final_model, 'LoanDefaulter_LightGBM.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eCgKS_6h3S1","executionInfo":{"status":"ok","timestamp":1764013051437,"user_tz":-120,"elapsed":87,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"25e008b8-ce83-4151-bc09-e0b68676db62"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['LoanDefaulter_LightGBM.pkl']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["\n","files.download('LoanDefaulter_LightGBM.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"M2KVbQGMjeTD","executionInfo":{"status":"ok","timestamp":1764013051446,"user_tz":-120,"elapsed":11,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"35bd0fff-c204-4c60-a126-f9e38fce105d"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a6941efb-9415-461c-adcf-d06b1b4349b7\", \"LoanDefaulter_LightGBM.pkl\", 3767348)"]},"metadata":{}}]},{"cell_type":"code","source":["joblib.dump(final_model, '/content/drive/MyDrive/LoanDefaulter_LightGBM.pkl')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2P_XuSW39dE","executionInfo":{"status":"ok","timestamp":1764013051646,"user_tz":-120,"elapsed":196,"user":{"displayName":"Mohammed Yasser","userId":"14237082109145793704"}},"outputId":"82c3ee6c-79f0-4517-cffa-1c9e92fe8880"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/LoanDefaulter_LightGBM.pkl']"]},"metadata":{},"execution_count":22}]}]}